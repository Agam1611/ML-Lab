{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQjz1knR9QCf",
        "outputId": "6ce4d47e-178e-494b-dc7f-133470942171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score using PCA with 2 components: 0.5166666666666667\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the digits dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Step 2: Split the data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Perform scaling (standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 4: Build PCA model with n_components = 2\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Step 5: Train a Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "logreg.fit(X_train_pca, y_train)\n",
        "\n",
        "# Step 6: Predict on the test set\n",
        "y_pred = logreg.predict(X_test_pca)\n",
        "\n",
        "# Step 7: Calculate the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output the accuracy score\n",
        "print(f\"Accuracy score using PCA with 2 components: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Step 1: Load dataset\n",
        "df = pd.read_csv(\"heart.csv\")  # Update path if needed\n",
        "\n",
        "# Step 2: Remove outliers using Z-score\n",
        "z_scores = np.abs(zscore(df.select_dtypes(include=[np.number])))\n",
        "df_no_outliers = df[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "# Step 3: Convert text to numbers (if needed)\n",
        "df_encoded = pd.get_dummies(df_no_outliers, drop_first=True)\n",
        "\n",
        "# Step 4: Apply scaling\n",
        "scaler = StandardScaler()\n",
        "target_col = 'HeartDisease'  # Update if different\n",
        "X = df_encoded.drop(target_col, axis=1)\n",
        "y = df_encoded[target_col]\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 5: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5a: Train multiple models and compare\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'SVM': SVC(),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "print(\"=== Accuracy without PCA ===\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n",
        "# Step 6: PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\n=== Accuracy with PCA (2 components) ===\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_pca, y_train_pca)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "    acc = accuracy_score(y_test_pca, y_pred)\n",
        "    print(f\"{name}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OZKHJl0_GeC",
        "outputId": "cbdd55a6-8a1e-4838-fe2b-11db29f0af9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Accuracy without PCA ===\n",
            "Logistic Regression: 0.8889\n",
            "SVM: 0.8889\n",
            "Random Forest: 0.8667\n",
            "\n",
            "=== Accuracy with PCA (2 components) ===\n",
            "Logistic Regression: 0.8722\n",
            "SVM: 0.8611\n",
            "Random Forest: 0.8333\n"
          ]
        }
      ]
    }
  ]
}